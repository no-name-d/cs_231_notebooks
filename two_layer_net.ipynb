{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Реализуем свёрточную нейросеть\n",
    "В этом упражнении мы реализуем полносвязную нейросеть для классификации и оценим её на датасете CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запустите эту ячейку для проверки работоспособности необходимых модулей.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cs231n.classifiers.neural_net import TwoLayerNet\n",
    "\n",
    "# Немного магии, чтобы заставить графики matplotlib появляться прямо внутри блокнота,\n",
    "# а не в новом окне.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # размер графиков по умолчанию\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Больше магии с дополнительными Python-модулями можно найти здесь\n",
    "# http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" относительная ошибка \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "Мы будем использовать класс `TwoLayerNet` из файла `neural_net.py`. Гиперпараметры находятся в переменной `self.params`. Ниже мы инициализируем \"игрушечные\" данные и модель для реализации нейросети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обратите внимание, что мы устанавливаем random.seed конкретным числом, чтобы повторять эксперименты.\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "    np.random.seed(0)\n",
    "    return TwoLayerNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "    np.random.seed(1)\n",
    "    X = 10 * np.random.randn(num_inputs, input_size)\n",
    "    y = np.array([0, 1, 2, 2, 1])\n",
    "    return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прямой проход: Вычисляем оценки\n",
    "Откройте файл `neural_net.py` и посмотрите на метод `TwoLayerNet.loss`. Это функция потерь: она берёт данные и веса, а затем вычисляет оценки классов, потери и градиенты. \n",
    "\n",
    "Реализуйте первую часть прямого прохода, которая использует весовые коэффициенты и смещения, чтобы вычислить оценки для всех входных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = net.loss(X)\n",
    "print('Ваши оценки:')\n",
    "print(scores)\n",
    "print()\n",
    "print('Корректные оценки:')\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print(correct_scores)\n",
    "print()\n",
    "\n",
    "# Разница должна быть очень маленькой, < 1e-7\n",
    "print('Разница между вашими оценками и корректными оценками:')\n",
    "print(np.sum(np.abs(scores - correct_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прямой проход: вычисляем потери\n",
    "В той же функции реализуйте вторую часть, которая вычисляет потери данных и регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.05)\n",
    "correct_loss = 1.30378789133\n",
    "\n",
    "# Должна быть очень маленькой, < 1e-12\n",
    "print('Разница между вашими оценками и корректными оценками:')\n",
    "print(np.sum(np.abs(loss - correct_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обратный проход\n",
    "Реализуйте остальную часть функции. Она должна вычислить градиент потерь по отношению к переменным `W1`, `b1`, `W2` и `b2`. Если вы правильно реализовали прямой проход, вы можете проверить обратный проход с помощью числового градиента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.gradient_check import eval_numerical_gradient\n",
    "\n",
    "# Используйте числовую проверку.\n",
    "# Если ваша реализация правильная, то разница между числовым и аналитическим градиентом должна быть\n",
    "# менее чем 1e-8 для всех переменных: W1, W2, b1 и b2.\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.05)\n",
    "\n",
    "# Все должны быть меньше 1e-8\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X, y, reg=0.05)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print('%s максимальная относительная погрешность: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем нейросеть\n",
    "Для обучения нейросети мы используем стохастический градиентный спуск (SGD). Посмотрите на функцию `TwoLayerNet.train` и заполните пропуски, чтобы реализовать процесс обучения. Вам также необходимо будет написать метод `TwoLayerNet.predict`, поскольку процесс обучения периодически выполняет прогнозы, чтобы отслеживать точность во время обучения.\n",
    "\n",
    "После этого запустите код ниже, чтобы обучить простую нейросеть. Вы должны получить потери обучения меньше 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = init_toy_model()\n",
    "stats = net.train(X, y, X, y,\n",
    "            learning_rate=1e-1, reg=5e-6,\n",
    "            num_iters=100, verbose=False)\n",
    "\n",
    "print('Финальные потери обучения: ', stats['loss_history'][-1])\n",
    "\n",
    "# Выводим график потерь\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "Теперь, когда вы реализовали двухслойную нейросеть, которая проходит градиентную проверку, пришло время загрузить ваш любимый CIFAR-10 и обучить нейросеть на реальных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "from cs231n.data_utils import load_CIFAR10\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    \"\"\"\n",
    "    Загружаем датасет CIFAR-10 и выполняем предварительную обработку данных.  \n",
    "    \"\"\"\n",
    "    # Загрузка данных\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    # Очищаем переменные, чтобы данные можно было загружать много раз \n",
    "    try:\n",
    "       del X_train, y_train\n",
    "       del X_test, y_test\n",
    "       print('Очистка предыдущих данных.')\n",
    "    except:\n",
    "       pass\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "        \n",
    "    # Разделяем данные на подвыборки\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Нормализуем данные\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    # Превращаем данные в строки\n",
    "    X_train = X_train.reshape(num_training, -1)\n",
    "    X_val = X_val.reshape(num_validation, -1)\n",
    "    X_test = X_test.reshape(num_test, -1)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Выводим размеры данных\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Объём обучающей выборки: ', X_train.shape)\n",
    "print('Число обучающих меток: ', y_train.shape)\n",
    "print('Объём оценочной выборки: ', X_val.shape)\n",
    "print('Число оценочных меток: ', y_val.shape)\n",
    "print('Объём тестовой выборки: ', X_test.shape)\n",
    "print('Число тестовых меток: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем нейросеть\n",
    "Для обучения мы снова будем использовать SGD. Кроме того, мы будем корректировать скорость обучения с помощью экспоненциального графика по мере оптимизации; после каждой эпохи мы будем снижать скорость обучения, умножая ее на скорость затухания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 50\n",
    "num_classes = 10\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Обучаем нейросеть\n",
    "stats = net.train(X_train, y_train, X_val, y_val,\n",
    "            num_iters=1000, batch_size=200,\n",
    "            learning_rate=1e-4, learning_rate_decay=0.95,\n",
    "            reg=0.25, verbose=True)\n",
    "\n",
    "# Делаем прогнозы на оценочной выборке\n",
    "val_acc = (net.predict(X_val) == y_val).mean()\n",
    "print('Точность оценки: ', val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отлаживаем обучение\n",
    "С параметрами по умолчанию, которые мы указали выше, вы должны получить точность около 0.29 для оценочной выборки. Это не очень хороший результат.\n",
    "\n",
    "Одна из стратегий, позволяющая понять, что не так - построить график функции потерь и точности для обучающей и оценочной выборок при оптимизации.\n",
    "\n",
    "Другая стратегия заключается в визуализации весов, которые были изучены на первом слое сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выводим график функции потерь и точности\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.vis_utils import visualize_grid\n",
    "\n",
    "# Визуализируем веса\n",
    "\n",
    "def show_net_weights(net):\n",
    "    W1 = net.params['W1']\n",
    "    W1 = W1.reshape(32, 32, 3, -1).transpose(3, 0, 1, 2)\n",
    "    plt.imshow(visualize_grid(W1, padding=3).astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_net_weights(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настраиваем гиперпараметры\n",
    "\n",
    "**В чём дело?** Глядя на приведенные выше визуализации, мы видим, что потери уменьшаются более или менее линейно - это может говорить о том, что скорость обучения слишком низкая. Более того, нет никакой разницы между точностью обучения и оценки. Значит, используемая нами модель слишком мала. С другой стороны, с большой моделью можно столкнуться с переобучением, которое проявится в очень большом разрыве между точностью обучения и оценки.\n",
    "\n",
    "**Настройка**: Настройка гиперпараметров и оценка того, как они будут влиять на эффективность модели - важная часть процесса обучения нейросетей, которую стоит регулярно практиковать. Ниже вы должны поэкспериментировать с различными значениями гиперпараметров, включая размер скрытого слоя, скорость обучения, количество эпох обучения и силу регуляризации. Вы также можете подумать о настройке снижения скорости обучения, но неплохой точности можно добиться и со значением по умолчанию.\n",
    "\n",
    "**Приблизительные результаты**: Вы должны стремиться к достижению точности классификации более 48% на оценочной выборке. 52% - в данном случае хороший результат.\n",
    "\n",
    "**Эксперимент**: Ваша цель в этом упражнении - получить как можно лучший результат на CIFAR-10. Не стесняйтесь использовать свои собственные методы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "best_net = None # сохраните сюда лучшую модель\n",
    "\n",
    "#################################################################################\n",
    "# TODO: Настроить гиперпараметры с помощью оценочной выборки и сохранить модель #\n",
    "# в переменную best_net.                                                        #\n",
    "#                                                                               #\n",
    "# Полезно будет использовать здесь те же графики, что мы применяли выше.        #\n",
    "# Они должны существенно отличаться от плохо настроенной нейросети.             #\n",
    "#                                                                               #\n",
    "# Лучше всего написать код для автоматического подбора гиперпараметров, чем     #\n",
    "# перебирать их вручную.                                                        #\n",
    "#################################################################################\n",
    "# *****START OF YOUR CODE*****\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE*****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация весов лучшей нейросети\n",
    "show_net_weights(best_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запускаем сеть на тестовой выборке\n",
    "Когда закончите с экспериментами, оцените финальную нейросеть на тестовой выборке. Вы должны получить точность выше 48%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (best_net.predict(X_test) == y_test).mean()\n",
    "print('Точность на тестовой выборке: ', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}